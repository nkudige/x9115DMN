# I. Abstract

This paper addresses about how to quantify how much one candidate solution dominates over an other solution or how a pool of candidate solution dominates over another pool of solution. To find which candidate is a better solution, we simply calculate the energy values and pick the one that is farthest from hell. It becomes extremely important to optimize the comparison between candidate solutions, as this function would be called the maximum number of times by the optimization algorithm. Comparing a pool of candidate solutions also needs to be fast, but not necessarily as fast as the comparison of candidate solutions.

# II. Background

### Differential Evolution

Differential Evolution is an algorithm that does not always guarantee an optimal solution, but is able to quickly reach an acceptable solution. Differential Evolution starts by initially generating a frontier by randomly generating candidates. After this step, it generates subsequent frontiers by updating the current frontier by generating new solutions that are a combination of candidates already existing in the frontier. If the newly generated candidate is better than the candidates used to generate this new solution, it gets replaced by this new solution. This goes on for a certain number of iterations and we now pick the best candidate solution from the pool frontier.

### Simulated Annealing

Simulated Annealing is a probabilistic technique for approximating the global optimum of a given function. In Simulated Annealing, we start with a random candidate solution and randomly search the sample space for a better solution. Each time a new random solution is generated, we compare the new candidate with the best solution and the previous solution and determine whether to jump to the new solution or not with a certain probability. Also, we time the algorithm becomes less crazy and the probability of jumping to a worse solution decreases.

### Max Walk Sat

Max Walk Sat is a local search algorithm. It is a lot less random than Simulated Annealing and is much simpler. It works by changing the values of one parameter at a time, while keeping the rest of the parameters fixed and always moves in the direction of better solution. It is possible to control/change the steps to move in the direction of the better solution. If the steps parameter is too high, it could miss a maxima or if it is too low, it could get caught in a local maxima. Also sometimes when the initially fixed parameters are not optimal, and when it finds out that the solution cannot be improved any better by varying the unfixed parameters, it tries to go back and change the fixed parameters and resume the algorithm. This is called retries.

# III. Introduction

The three types of comparator functions used for this project are type1, type2 and type3.

The type1 comparator is the most frequently used comparison operation by a optimizer. The type1 comparator function is called every time a new candidate solution is called. The type1 comparator function thus needs to be very fast as it is called very frequently by the optimizer. The type1 comparator does not quantify the domination of one solution over the other, but gives a simple yes or no solution. Binary domination works well when there are only 2 parameters. But when there are multiple parameters, continuous domination will be used.

Type 2 comparator is used to compare a pool of candidate solutions generated by an era. Every time an era is generated, this function is called to check whether to see if the algorithm is proceeding in the right direction or not. Each time we find that the algorithm has not improved the candidate solutions, we decrement the life and we terminate the execution once we are out of lives. Some of the commonly used type2 comparator is a12 statistic. a12 was used in our project to compare various eras of our solution. This is run less frequently than the type1 operator, but is run more than the type3 operator.

Type3 comparator is basically used to compare the final eras generated by two different algorithms. This is run at the end of each algorithm to identify which algorithm performed better. For type3 comparator, different baselines are generated each time and the optimizer is run with different baselines. The actual differences between the eras are used to rank the different solutions.

# IV. The Process

The goal of the project is to compare the various algorithms that were implemented in code 4,5,6 & 7 and generate type1, type2 and type3 statistics and compare which of the algorithms performed better. To perform this experiment, we ran the algorithm each time with different baselines. Each pool of the candidate solutions generated by an optimizer was saved in an era and was compared with the previous era using the type2 comparator. Each time we found that there was no improvement we decremented the value of lives and terminated the algorithm when the lives count was 0. If the era improved, we improved the lives by 5. With this approach we were able to terminate our algorithm earlier than usual, whenever we found that the we were not progressing towards a better solution. To compare the candidate solutions generated by different 
optimization algorithms, we used a rdiv comparator to compare the candidate solutions from different optimizers.

# V. Results
### SA
![alt tag](https://github.com/nkudige/x9115DMN/blob/master/hw/code/8/output_SA.PNG)

### MWS
![alt tag](https://github.com/nkudige/x9115DMN/blob/master/hw/code/8/MWS_Output.PNG)


# VI. THREATS TO VALIDITY

The algorithms used for comparison, namely DE and Simulated Annealing  generate neighboring solutions completely randomly and even further continues with the search process in a random fashion. This would not allow the search process to quickly proceed in the right direction. This would rather cause the algorithm to wander about a lot, even though when it knows the direction in which it is improving. On the other hand, MaxWalkSat is a local search algorithm, which fixes on some of the parameters and only varies the remaining ones and only moves in the direction of improvements (similar to a hill climbing approach). This could cause the algorithm to get caught in a local maxima. It would be great if we could combine the ideas of both the algorithm and generate an algorithm that would combine the two techniques to reach a global optimal solution.

